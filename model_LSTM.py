# -*- coding: utf-8 -*-
"""modèle LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14ayA3gaXXQF1wRiJ_fc-klht-ojh71MW
"""

import yfinance as yf
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsolutePercentageError, MeanAbsoluteError
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import load_model
import mlflow


def df_to_X_y(df, window_size=5):
  df_as_np = df.to_numpy()
  X = []
  y = []
  for i in range(len(df_as_np)-window_size):
      row = [[a] for a in df_as_np[i:i+5]]
      X.append(row)
      label = df_as_np[i+5]
      y.append(label)
  return np.array(X), np.array(y)

if __name__ == "__main__":


    EXPERIMENT_NAME="wallet_17_model_Steve"
    APP_URI = "https://mlflow-sca-app.herokuapp.com/"
    mlflow.set_tracking_uri(APP_URI)

    mlflow.set_experiment(EXPERIMENT_NAME)
    experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)
    #client = mlflow.tracking.MlflowClient()


    mlflow.tensorflow.autolog()
    #mlflow.log_metric('MeanAbsoluteError', MeanAbsoluteError)
    #mlflow.log_metric("MeanSquaredError", MeanSquaredError)
    #mlflow.log_metric("MeanAbsolutePercentageError", MeanAbsolutePercentageError)


    #run = client.create_run(experiment.experiment_id)

    with mlflow.start_run():


        data = yf.download(tickers = "EDF.PA ENGI.PA RWE.F EOAN.F NNGF.F",
                        period= "10y",
                            end = "2022-03-23",
                            interval = "1d",
                            group_by="ticker",
                        prepost=True,
                            auto_adjust = True)
        #j'importe le dataset avec tous mes actifs divisé chacun en 5 colonnes correspondant au PO, PC, High, Low et Volume

        data = data.interpolate(method='linear')


        column_to_drop = dict(data.columns)
        list_actifs = list(column_to_drop.keys()) #nous permet d'obtenir le noms des actifs

        data = data.drop('Volume', axis=1, level=1)

        '''plt.figure(figsize=(16, 8), dpi=150)

        data[('EOAN.F', 'Close')].plot(label='EOAN.F', color='blue')
        data[('EDF.PA', 'Close')].plot(label='EDF.PA', color='orange')
        data[('RWE.F', 'Close')].plot(label='RWE.F', color='green')
        data[('ENGI.PA', 'Close')].plot(label='ENGI.PA', color='red')
        data[('NNGF.F', 'Close')].plot(label='EOAN.F', color='purple')

        plt.title('Close par actifs')
        plt.xlabel('Date')
        plt.legend'''

        target = data[('ENGI.PA','Close')] #Nous allons prévoir le close pour l'actif: ENGI.PA

        WINDOW_SIZE = 5
        X, y = df_to_X_y(target, WINDOW_SIZE)

        rows_for_X_train = int(0.7*X.shape[0])
        rows_for_y_train = int(0.6*(X.shape[0]-rows_for_X_train)) + rows_for_X_train
        rows_for_X_test = X.shape[0] - rows_for_y_train

        X_train, y_train = X[:rows_for_X_train], y[:rows_for_X_train] #on utilise 0.7% des lignes de X
        X_val, y_val = X[rows_for_X_train:rows_for_y_train], y[rows_for_X_train:rows_for_y_train]
        X_test, y_test = X[rows_for_y_train:], y[rows_for_y_train:]

        model1 = Sequential()
        model1.add(LSTM(64,activation='relu', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))
        model1.add(LSTM(32, activation='relu', return_sequences=False))
        model1.add(Dense(8, 'relu'))
        model1.add(Dense(1, 'linear'))

        model1.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.01), metrics=[MeanAbsolutePercentageError(),RootMeanSquaredError(),MeanAbsoluteError()])

        model1.summary()

        cp = ModelCheckpoint('modelSteve_1/', save_best_only=True)

        model1.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, callbacks=[cp])

        model1 = load_model('modelSteve_1/')

        

        train_predictions = model1.predict(X_train).flatten()
        train_results = pd.DataFrame(data={'Train Predictions':train_predictions, 'Actuals':y_train}, index=data.index[WINDOW_SIZE:rows_for_X_train+5])
        val_predictions = model1.predict(X_val).flatten()
        val_results = pd.DataFrame(data={'Val Predictions':val_predictions, 'Actuals':y_val}, index=data.index[rows_for_X_train+WINDOW_SIZE:rows_for_y_train+WINDOW_SIZE])
        test_predictions = model1.predict(X_test).flatten()
        test_results = pd.DataFrame(data={'Test Predictions':test_predictions, 'Actuals':y_test},index=data.index[rows_for_y_train+WINDOW_SIZE:])
 

        #test_results.idxmax()
        #(test_results['Actuals'] - test_results['Test Predictions']).idxmax()
        # #test_results.loc['2022-02-25']

        '''plt.figure(figsize=(16, 8), dpi=150)

        train_results['Train Predictions'].plot(label='Train Predictions', color='red')
        train_results['Actuals'].plot(label='Actuals', color='green')
        val_results['Val Predictions'].plot(label='Val Predictions', color='purple')
        val_results['Actuals'].plot(label='Actuals', color='blue')
        test_results['Test Predictions'].plot(label='Test Predictions', color='orange')
        test_results['Actuals'].plot(label='Actuals', color='yellow')

        plt.title("predictions")
        plt.xlabel("Date")
        plt.xlim('2020','2021')
        plt.legend()'''

